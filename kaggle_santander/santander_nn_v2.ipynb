{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!/usr/bin/python\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(color_codes=True)\nimport datetime\n\n#import standard ML libraries\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.utils.multiclass import unique_labels\n\n#keras NN libraries:\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom keras import regularizers\nfrom keras.constraints import max_norm\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Binarizer, KernelCenterer\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\n\nfrom umap import UMAP\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\n#import specific classifiers\nfrom sklearn.ensemble import RandomForestClassifier\nprint('Lib import check positive ++.')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.csv')\nprint(\"Test data :\", test_data.shape)\ntrain_data = pd.read_csv('../input/train.csv')\nprint(\"Train data :\", train_data.shape)\ntarget = pd.read_csv('../input/sample_submission.csv')\nprint(\"Target :\", target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b4ea3663dc6cdfdaa6e4fa4bc82294b52c1e680c"},"cell_type":"code","source":"#check a sample output of first few rows:\nprint(train_data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"224d0b1794e6bfe33538f75ad447cce75a9ef87e"},"cell_type":"code","source":"def data_target_split (df):\n    X = df.iloc[:,2:].values\n    y = df.iloc[:,1].values\n    return X, y\nX, y = data_target_split(train_data)\n#select the right part of the final test data\ntest_data = test_data.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0156dfe2d4389b8b0b91e6e52327a501d6148823"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 329)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e249287a65cddc88f54aee8b22f00deab366099"},"cell_type":"code","source":"#scale the X_train with Min Max scaler:\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_tr_scaled = scaler.transform(X_train)\nX_tst_scaled = scaler.transform(X_test)\n\n#check the output shapes:\nX_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cc0341e4b0217716afe9b54e29c725f5bcaea63"},"cell_type":"code","source":"def make_model():\n    model = Sequential()\n\n    #input \n    model.add(Dense(200, input_dim=200, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint = max_norm(5.)))\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.2))\n\n    #1 \n    model.add(Dense(200, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.1))\n    \n    #2\n    model.add(Dense(100, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.1))\n    \n    #2\n    model.add(Dense(50, kernel_initializer = 'uniform', \n                    kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n    model.add(Activation('tanh'))\n    model.add(Dropout(0.1))\n    \n    #output\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", auc])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43a8d7d37a6191b3b7e5e885fc6d2ea160adf067"},"cell_type":"code","source":"def train_model_iterate(X, y, test):\n    model = make_model()\n    pred = pd.DataFrame()\n    for i in range(1, 3):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=15600, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr1 = train_model_iterate(X, y, test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr1['mean'] = pr1.mean(axis=1)\npr1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72424964d0445ef1007ff1d22dae1d09735bcef1"},"cell_type":"code","source":"ver = '1.1'\nfilename = 'submission_{}_{}_'.format(ver, datetime.datetime.now().strftime('%Y-%m-%d'))\ntarget['target'] = pr1['mean']\ntarget.to_csv(filename+'1'+'.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}